<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <title>Pattern AR</title>

  <!-- iPhone-friendly pinned versions -->
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.4.5/aframe/build/aframe-ar.js"></script>

  <style>
    html, body {
      width: 100%;
      height: 100%;
      margin: 0;
      overflow: hidden;
      background: #000;
      font-family: system-ui, -apple-system, Segoe UI, Roboto;
    }

    #sceneMount {
      position: fixed;
      inset: 0;
      width: 100%;
      height: 100%;
      z-index: 0;
    }

    /* Only size A-Frame’s render canvas (NOT all canvases) */
    .a-canvas {
      position: fixed !important;
      inset: 0 !important;
      width: 100% !important;
      height: 100% !important;
    }

    /* AR.js camera video element (force inline + fullscreen) */
    video {
      position: fixed !important;
      inset: 0 !important;
      width: 100% !important;
      height: 100% !important;
      object-fit: cover !important;
    }

    #overlay{
      position: fixed; inset: 0; z-index: 50;
      display:flex; align-items:center; justify-content:center;
      background: rgba(0,0,0,.75);
      color: rgba(255,255,255,.92);
      text-align:center;
      padding: 18px;
    }
    .card{
      max-width: 420px;
      background: rgba(255,255,255,.08);
      border: 1px solid rgba(255,255,255,.18);
      border-radius: 18px;
      padding: 16px;
    }
    .btn{
      display:inline-block;
      margin-top: 12px;
      background: rgba(255,255,255,.22);
      border: 1px solid rgba(255,255,255,.25);
      color: rgba(255,255,255,.92);
      padding: 10px 12px;
      border-radius: 12px;
      cursor:pointer;
      user-select:none;
      font-size: 14px;
    }
    #hint{
      position: fixed; left: 12px; right: 12px; bottom: 12px;
      z-index: 40;
      background: rgba(0,0,0,.45);
      border: 1px solid rgba(255,255,255,.18);
      color: rgba(255,255,255,.92);
      padding: 10px 12px;
      border-radius: 14px;
      backdrop-filter: blur(8px);
      text-align:center;
    }
  </style>
</head>

<body>
  <div id="overlay">
    <div class="card">
      <div style="font-weight:700; font-size:18px; margin-bottom:6px;">Step 3: AR View</div>
      <div style="opacity:.9">Tap Start, allow camera, then point at your printed marker.</div>
      <div class="btn" id="start">Start AR</div>
      <div class="btn" onclick="location.href='./'">Back</div>
    </div>
  </div>

  <div id="hint">Loading pattern…</div>

  <!-- Hidden texture canvas (NxN) -->
  <canvas id="texCanvas" width="16" height="16" style="display:none"></canvas>

  <div id="sceneMount"></div>

  <script>
    // A-Frame component: canvas as a live texture
    AFRAME.registerComponent("dynamic-canvas-texture", {
      schema: { canvas: { type: "selector" }, pixelate: { type: "boolean", default: true } },
      init() {
        const canvas = this.data.canvas;
        const texture = new THREE.CanvasTexture(canvas);

        if (this.data.pixelate) {
          texture.magFilter = THREE.NearestFilter;
          texture.minFilter = THREE.NearestFilter;
        }

        texture.wrapS = THREE.ClampToEdgeWrapping;
        texture.wrapT = THREE.ClampToEdgeWrapping;

        const apply = () => {
          const mesh = this.el.getObject3D("mesh");
          if (!mesh) return;
          mesh.traverse((node) => {
            if (!node.isMesh) return;
            node.material.map = texture;
            node.material.needsUpdate = true;
          });
          this.texture = texture;
        };

        if (this.el.getObject3D("mesh")) apply();
        else this.el.addEventListener("object3dset", apply);
      },
      tick() {
        if (this.texture) this.texture.needsUpdate = true;
      }
    });

    const hint = document.getElementById("hint");
    const texCanvas = document.getElementById("texCanvas");
    const tctx = texCanvas.getContext("2d");

    // Load saved pattern from Step 2
    const png = localStorage.getItem("pattern_png");
    const nStr = localStorage.getItem("pattern_N") || "16";
    const N = Math.max(2, parseInt(nStr, 10) || 16);

    async function loadPattern() {
      if (!png) {
        hint.textContent = "No saved pattern found. Go back and create one first.";
        return false;
      }
      texCanvas.width = N;
      texCanvas.height = N;

      const img = new Image();
      img.src = png;
      await img.decode();

      tctx.imageSmoothingEnabled = false;
      tctx.clearRect(0,0,N,N);
      tctx.drawImage(img, 0, 0, N, N);

      hint.textContent = "Ready. Tap Start AR, then point at the marker.";
      return true;
    }

    // iOS Safari fix: force AR.js camera <video> to be inline + playing
    function forceIOSInlineCameraVideo() {
      const v = document.querySelector("video");
      if (!v) return false;

      v.setAttribute("playsinline", "");
      v.setAttribute("webkit-playsinline", "");
      v.setAttribute("muted", "");
      v.setAttribute("autoplay", "");
      v.muted = true;
      v.autoplay = true;
      v.playsInline = true;

      const p = v.play();
      if (p && p.catch) p.catch(() => {});
      return true;
    }

    function mountScene() {
      // Cache bust so iPhone doesn’t keep using an old marker pattern
      const patternUrl = "markers/pattern.patt?v=4";

      document.getElementById("sceneMount").innerHTML = `
        <a-scene
          background="transparent: true"
          embedded
          vr-mode-ui="enabled: false"
          renderer="antialias: true; alpha: true"
          arjs="sourceType: webcam; videoTexture: true; debugUIEnabled: false;">

          <a-marker
            id="marker"
            type="pattern"
            url="${patternUrl}"
            emitevents="true">

            <a-plane
              rotation="-90 0 0"
              position="0 0.01 0"
              width="1.05"
              height="1.05"
              material="shader: flat; transparent: true; opacity: 0.98; side: double;"
              dynamic-canvas-texture="canvas: #texCanvas; pixelate: true;">
            </a-plane>

            <a-ring
              rotation="-90 0 0"
              position="0 0.009 0"
              radius-inner="0.52"
              radius-outer="0.54"
              material="shader: flat; color: #ffffff; opacity: 0.35; transparent: true; side: double;">
            </a-ring>

          </a-marker>

          <a-entity camera look-controls="enabled: false"></a-entity>
        </a-scene>
      `;

      // Try a few times until AR.js injects the <video>
      let tries = 0;
      const timer = setInterval(() => {
        tries++;
        if (forceIOSInlineCameraVideo()) {
          hint.textContent = "Camera running ✅ Point at the marker.";
          clearInterval(timer);
        } else if (tries > 50) {
          hint.textContent = "Camera video not starting. Make sure Safari has Camera permission, then reload.";
          clearInterval(timer);
        }
      }, 100);

      // Marker events
      setTimeout(() => {
        const marker = document.getElementById("marker");
        if (!marker) return;

        marker.addEventListener("markerFound", () => {
          console.log("markerFound");
          hint.textContent = "Marker found ✅ Pattern placed in AR.";
        });

        marker.addEventListener("markerLost", () => {
          console.log("markerLost");
          hint.textContent = "Marker lost — point back at the marker.";
        });
      }, 0);
    }

    (async () => {
      await loadPattern();

      document.getElementById("start").addEventListener("click", () => {
        document.getElementById("overlay").style.display = "none";
        mountScene();

        // extra immediate attempt (inside user gesture = best chance on iOS)
        forceIOSInlineCameraVideo();
      });
    })();
  </script>
</body>
</html>
